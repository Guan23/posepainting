
python inference.py
project.py是读取kitti各数据，调用inference，并且在二维图像上可视化的py文件
function.py是融合模块算法基础
后期3d点云的可视化，需要用到mayavi（python）或者把点云存成一个txt文件，用c++的pcl库来显示以及进行一些后处理

-----------------------20211119-22:14----------------------
mayavi的可视化已经用起来了，尽管不好用，但测试足够了，
create_one_man_joint_3d和points_2d_to_3d这两个函数应该还有点bug，生成的3D关节点是倒立的，而且坐标明显不对，
应该是欧式距离算法那边选错点了，另外那两个范围阈值也没有仔细调整，

1、我觉得不如直接上膨胀选点算法，欧式距离只留中心点那个，
2、另外，多个符合条件的激光点确实要另存一个数组，然后比较他们的四维信息，删除错误点，
3、可视化函数那边多加一个颜色形参，把17个关节点vstack到原点云后，单独设置大小和颜色。

-----------------------20211120-01:24----------------------
1、测试了一晚上，找到bug了，就是在筛选点的时候，要把所有列表都进行筛选，否则下标就对应不上
筛选点共有两次，第一次是点投影到图像上时，只留下在图像范围内的点，第二次是只留下在人体检测框内的点。

2、基于与关节点的距离进行选点的部分被放弃了，因为关节点在身体边缘，很容易选到墙上，只留了中心点

3、中心点的生成不再用所有点，而是只挑了7个点，分别是鼻子，左右肩，左右胯，左右膝

4、满足条件的点会存一个列表，目前中心点半径阈值设置为1.7^2（假设人平均身高1.7m）
第一张图有3个点入选，深度为8.45, 8.487, 8.6，可以人为将此深度增加一部分（毕竟激光打的是表面点，增加的部分可根据此人的高度而来）

-----------------------20211120-18:24----------------------
1、取depth时，均值改中位数了，避免了错误点的干扰

2、求中心点的关键点减少为6个，把鼻子取消了

3、中心距离阈值改为4.5,后期打算改成变量而非定值

4、写了3D关节点的bias数组，因为每个关节点所在位置的人体厚度不一，激光点打的又是表面，所以可以人为加上bias，使关节点更靠近人体内部

-----------------------20211130-10:04----------------------
1、按照标准人体比例（整体小一号），生成人体膨胀掩膜，初步把人体分成了11个部位，分别为如下部分：
头、脖子、躯干、左大臂、左小臂、右大臂、右小臂、左大腿、左小腿、右大腿、右小腿
每个部位赋予了不同的掩码，分别是1～11，其余为0（代表背景）。

2、把3D点云投影到掩膜上，对其掩码进行判断，1～11存入各自的候选点列表中，把2D点分成11个身体部位。

3、判断11个候选列表（对应11个身体部位），依然是判断中位数与最小值的差值是否超过5%（可调），不超过选中位数，超过选最小值。

4、保留了第一版中的中心点，判断条件没变，也获取了其深度信息，但不再作为判断点云是否是人体点的依据了。

5、对17个关节点赋予11个不同的深度值，目前采取如下分配方案：
鼻子、双眼、双耳-----头部的深度
左右肩膀-----脖子和躯干深度的平均数
左右髋-----躯干和中心点深度的平均数
左右肘-----左右大臂的深度
左右腕-----左右小臂的深度
左右膝-----左右大腿的深度
左右踝-----左右小腿的深度

-----------------------20211130-15:04----------------------
可以参照waymo和google在2021年12月22出的新论文，在2D图上以某个关节点为圆心设定一个半径r，取圆内所有点的深度平均值为w，赋予该关节点，
此即该论文的伪数据集生成的方式。
首先，论文使用的是waymo的数据集，又新又多又好
其次，论文中伪3D标签生成需要满足3个前提
1、假设点云足够多，至少保证每个关节点的临域内至少有1个点
2、假设人体表面足够光滑，也就是每个关节点临域内的其他点，深度之间没有太大的变化
3、外参矩阵是可靠的

但是，对于kitti数据集，1和3这两个前提是很难保证的。

-----------------------20220411-16:14----------------------
经过在长沙智能驾驶研究院的实习，了解到了目前无人驾驶行业的一些现状，之所以多传感器前融合未曾投入实际使用，最大的一个障碍，
在于实时的内外参标定仍有较大误差，尤其是外参，因为行驶过程中不可避免会出现震动的现象，导致各传感器之间发生相对位移。
同理，kitti、nuscenes等这些公开数据集，他们的calibrations也并不是100%正确的，也有十几帧或几十帧数据，其calibration尤其是外参是错误的，
在投影时很明显能看出来，点云投射发生偏移了，这种问题目前无法解决。

所以在kitti数据集上统计行人位置误差时，总有那么几十帧的误差非常大，可以忽略不计，重点是代码的逻辑正确，没必要为了涨点而故意增加参数

































